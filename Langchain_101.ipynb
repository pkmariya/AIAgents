{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9XpLu9kv3IDnP0nk0i0Nc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkmariya/AIAgents/blob/main/Langchain_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain"
      ],
      "metadata": {
        "id": "A38V1HFVzLJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Langchain - Message Types"
      ],
      "metadata": {
        "id": "1SXRw2OzzF4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BdoSs_nkwNH5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [AIMessage(content=\"Hi, how can I help you?\", name=\"AIModel\")]"
      ],
      "metadata": {
        "id": "gptAEPU3wTWy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fxgr1y3wpu5",
        "outputId": "385307be-d3c7-4fb3-bef4-c894af10667b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Hi, how can I help you?', additional_kwargs={}, response_metadata={}, name='AIModel')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(HumanMessage(content=\"What is the meaning of life?\", name=\"Mariya\"))"
      ],
      "metadata": {
        "id": "lPiJ0JwUwxhB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def converse_with_AI():\n",
        "  for m in messages:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "id": "_8K4-IVDw6mN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(AIMessage(content=\"The meaning of life is being useful to others.\", name=\"AIModel\"))"
      ],
      "metadata": {
        "id": "IURsce3zxZ0U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converse_with_AI()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3abMweuxoeu",
        "outputId": "7c53cd49-9c69-4966-cb6c-299520635414"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: AIModel\n",
            "\n",
            "Hi, how can I help you?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Mariya\n",
            "\n",
            "What is the meaning of life?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: AIModel\n",
            "\n",
            "The meaning of life is being useful to others.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: AIModel\n",
            "\n",
            "The meaning of life is being useful to others.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Langchain - Chat Models"
      ],
      "metadata": {
        "id": "ipunQPFMzPyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass"
      ],
      "metadata": {
        "id": "kZSiTgPhx0NM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV8zt6xt5ETH",
        "outputId": "e186cac3-5b28-430d-a49b-91aa313417d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROQ_API_KEY··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPwpYevs5kXb",
        "outputId": "3d874fed-f05d-4095-8d93-2c3512715b18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "rHfD-2kM5blP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    verbose=True,\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ],
      "metadata": {
        "id": "wNqKY8zv5iWm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(messages)"
      ],
      "metadata": {
        "id": "SYqBMx-c6Qir"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKybVCET6Tqi",
        "outputId": "7a14da01-828b-4d2a-8497-e5fa48f62495"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_tokens': 80, 'output_tokens': 1, 'total_tokens': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.response_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vss07X5765Ek",
        "outputId": "973c1ccf-8aad-48b4-d645-6860443929b9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 1,\n",
              "  'prompt_tokens': 80,\n",
              "  'total_tokens': 81,\n",
              "  'completion_time': 0.006402486,\n",
              "  'completion_tokens_details': None,\n",
              "  'prompt_time': 0.007146079,\n",
              "  'prompt_tokens_details': None,\n",
              "  'queue_time': None,\n",
              "  'total_time': 0.013548565},\n",
              " 'model_name': 'llama-3.3-70b-versatile',\n",
              " 'system_fingerprint': 'fp_68f543a7cc',\n",
              " 'service_tier': 'on_demand',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None,\n",
              " 'model_provider': 'groq'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SH7PZM8F7a5H",
        "outputId": "312ba457-93f0-4f5d-b070-695702c3b1fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMcBSjIv7eYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}